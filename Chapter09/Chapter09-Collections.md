
# فصل ۹. کالکشن‌ها

استفاده از کالکشن‌های مناسب در برنامه‌های همزمان (Concurrent) ضروری است.

من درباره‌ی کالکشن‌های استانداردی مثل `List<T>` صحبت نمی‌کنم؛ فرض می‌کنم با آن‌ها آشنا هستی. هدف این فصل معرفی کالکشن‌های جدیدتری است که مشخصاً برای استفاده‌ی همزمان یا غیرهمزمان طراحی شده‌اند.

## کالکشن‌های تغییرناپذیر (Immutable)

نمونه‌هایی از کالکشن هستند که هرگز تغییر نمی‌کنند. در نگاه اول، این کاملاً بی‌فایده به نظر می‌رسد؛ اما در واقع بسیار مفیدند، حتی در برنامه‌های تک‌ریسمانی و غیرهمزمان‌نشده.

عملیات فقط-خواندنی (مثل پیمایش) مستقیماً روی نمونه‌ی تغییرناپذیر انجام می‌شوند. عملیات نوشتن (مثل افزودن یک آیتم) به‌جای تغییر نمونه‌ی موجود، یک نمونه‌ی تغییرناپذیر جدید برمی‌گرداند. این کار آن‌قدرها هم که در ابتدا به نظر می‌رسد پرهزینه نیست، چون در اکثر مواقع کالکشن‌های تغییرناپذیر بیشتر حافظه‌شان را به‌صورت اشتراکی استفاده می‌کنند. علاوه بر این، کالکشن‌های تغییرناپذیر مزیت ایمنی ضمنی در دسترسی از چندین ریس‌مان را دارند؛ چون قابل تغییر نیستند، نخ-ایمن (thread-safe) هستند.

> **نکته**
> کالکشن‌های تغییرناپذیر در بسته‌ی NuGet با نام `System.Collections.Immutable` موجودند.

کالکشن‌های تغییرناپذیر جدید هستند، اما باید در توسعه‌های جدید در نظر گرفته شوند مگر این‌که به نمونه‌ی قابل‌تغییر نیاز داشته باشید. اگر با کالکشن‌های تغییرناپذیر آشنا نیستید، توصیه می‌کنم با دستورعمل ۹.۱ شروع کنید، حتی اگر به پشته (stack) یا صف (queue) نیاز ندارید، زیرا چند الگوی رایج را پوشش می‌دهم که همه‌ی کالکشن‌های تغییرناپذیر از آن‌ها پیروی می‌کنند.

راه‌های ویژه‌ای برای ساخت بهینه‌ی یک کالکشن تغییرناپذیر با تعداد زیادی عنصر موجود وجود دارد؛ کدهای نمونه در این دستورعمل‌ها فقط عناصر را یکی‌یکی اضافه می‌کنند. مستندات MSDN جزئیات ساخت بهینه‌ی کالکشن‌های تغییرناپذیر را دارد، اگر لازم است راه‌اندازی اولیه‌ی خود را سریع‌تر کنید.

## کالکشن‌های نخ-ایمن

این نمونه‌های کالکشنِ قابل‌تغییر را می‌توان به‌طور هم‌زمان توسط چندین ریس‌مان تغییر داد. کالکشن‌های نخ-ایمن از ترکیبی از قفل‌های ریزدانه و تکنیک‌های بی‌قفل (lock-free) استفاده می‌کنند تا اطمینان دهند ریس‌مان‌ها برای حداقل زمان ممکن مسدود می‌شوند (و معمولاً اصلاً مسدود نمی‌شوند). برای بسیاری از کالکشن‌های نخ-ایمن، پیمایش کالکشن یک اسنپ‌شات از کالکشن ایجاد می‌کند و سپس همان اسنپ‌شات را پیمایش می‌کند. مزیت کلیدی کالکشن‌های نخ-ایمن این است که می‌توان به‌طور ایمن از چندین ریس‌مان به آن‌ها دسترسی داشت، در حالی که عملیات تنها برای مدت کوتاهی، اگر اصلاً، کد شما را مسدود می‌کند.

## کالکشن‌های تولیدکننده/مصرف‌کننده

این نمونه‌های کالکشنِ قابل‌تغییر با هدفی مشخص طراحی شده‌اند: اجازه دادن به تولیدکننده‌ها (احتمالاً متعدد) برای هل دادن آیتم‌ها به کالکشن، در حالی که مصرف‌کننده‌ها (احتمالاً متعدد) بتوانند آیتم‌ها را از کالکشن بیرون بکشند. بنابراین به‌عنوان پلی بین کد تولیدکننده و کد مصرف‌کننده عمل می‌کنند و همچنین گزینه‌ای برای محدود کردن تعداد آیتم‌ها در کالکشن دارند.

کالکشن‌های تولیدکننده/مصرف‌کننده می‌توانند API مسدودکننده یا غیرهمزمان داشته باشند. برای مثال، وقتی کالکشن خالی است، یک کالکشن تولیدکننده/مصرف‌کننده‌ی مسدودکننده، ریس‌مان مصرف‌کننده‌ی فراخوان را تا زمانی که آیتم دیگری اضافه شود، مسدود می‌کند؛ اما یک کالکشن تولیدکننده/مصرف‌کننده‌ی غیرهمزمان به ریس‌مان مصرف‌کننده‌ی فراخوان اجازه می‌دهد تا به‌صورت غیرهمزمان منتظر بماند تا آیتم دیگری اضافه شود.

تعدادی کالکشن تولیدکننده/مصرف‌کننده‌ی مختلف در دستورعمل‌های این فصل استفاده شده‌اند و هر کدام مزایای متفاوتی دارند. جدول ۹-۱ می‌تواند در تعیین این‌که کدام را باید استفاده کنید، مفید باشد.

### جدول ۹-۱. کالکشن‌های تولیدکننده/مصرف‌کننده

| ویژگی                   | Channels | BlockingCollection<T> | BufferBlock<T> | AsyncProducer-ConsumerQueue<T> | AsyncCollection<T> |
| :----------------------- | :------: | :--------------------: | :------------: | :------------------------------: | :----------------: |
| معنای صف (Queue semantics)  |    ✓     |           ✓            |       ✓        |                ✓                 |         ✓          |
| معنای پشته/کیسه (Stack/bag semantics) |    ✗     |           ✓            |       ✗        |                ✗                 |         ✓          |
| API همگام (Synchronous)    |    ✓     |           ✓            |       ✓        |                ✓                 |         ✓          |
| API غیرهمزمان (Asynchronous) |    ✓     |           ✗            |       ✓        |                ✓                 |         ✓          |
| حذف آیتم‌ها هنگام پر بودن  |    ✓     |           ✗            |       ✗        |                ✗                 |         ✗          |
| تست‌شده توسط مایکروسافت |    ✓     |           ✓            |       ✓        |                ✗                 |         ✗          |

> **نکته**
> `Channels` در بسته‌ی NuGet با نام `System.Threading.Channels` موجود است، `BufferBlock<T>` در بسته‌ی NuGet برای `System.Threading.Tasks.Dataflow`، و `AsyncProducerConsumerQueue<T>` و `AsyncCollection<T>` در بسته‌ی NuGet با نام `Nito.AsyncEx`.

---

## ۹.۱ پشته‌ها و صف‌های تغییرناپذیر

### مسئله

به یک پشته یا صفی نیاز دارید که خیلی زیاد تغییر نکند و بتوان با اطمینان از چندین نخ (thread) به آن دسترسی داشت.

برای مثال، می‌توان از صف به‌عنوان دنباله‌ای از عملیات قابل اجرا استفاده کرد و از پشته به‌عنوان دنباله‌ای از عملیات بازگشت (undo).

### راه‌حل

پشته‌ها و صف‌های تغییرناپذیر ساده‌ترین کالکشن‌های تغییرناپذیر هستند. آن‌ها از نظر رفتار بسیار شبیه `Stack<T>` و `Queue<T>` استاندارد عمل می‌کنند. از نظر کارایی، پشته‌ها و صف‌های تغییرناپذیر همان پیچیدگی زمانی پشته‌ها و صف‌های استاندارد را دارند؛ با این حال، در سناریوهای ساده‌ای که کالکشن‌ها مکرراً به‌روزرسانی می‌شوند، پشته‌ها و صف‌های استاندارد سریع‌ترند.

پشته‌ها ساختار داده‌ای «اول-داخل، آخر-خارج» هستند. کد زیر یک پشته‌ی تغییرناپذیر خالی می‌سازد، دو آیتم را push می‌کند، آیتم‌ها را پیمایش می‌کند و سپس یک آیتم را pop می‌کند:

```csharp
ImmutableStack<int> stack = ImmutableStack<int>.Empty;
stack = stack.Push(13);
stack = stack.Push(7);
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
foreach (int item in stack)
    Trace.WriteLine(item);
int lastItem;
stack = stack.Pop(out lastItem);
// lastItem == 7
```

توجه کنید که در مثال، ما متغیر محلی `stack` را مرتب بازنویسی می‌کنیم. کالکشن‌های تغییرناپذیر الگویی را دنبال می‌کنند که در آن یک کالکشنِ به‌روزشده برگردانده می‌شود؛ ارجاع به کالکشن اصلی بدون تغییر می‌ماند. این یعنی وقتی به نمونه‌ی خاصی از یک کالکشن تغییرناپذیر ارجاع دارید، آن نمونه هرگز تغییر نخواهد کرد. مثال زیر را در نظر بگیرید:

```csharp
ImmutableStack<int> stack = ImmutableStack<int>.Empty;
stack = stack.Push(13);
ImmutableStack<int> biggerStack = stack.Push(7);
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
foreach (int item in biggerStack)
    Trace.WriteLine(item);
// فقط "13" را نمایش می‌دهد.
foreach (int item in stack)
    Trace.WriteLine(item);
```

در پشت صحنه، این دو پشته حافظه‌ای را که برای نگهداری آیتم 13 استفاده شده به‌صورت مشترک به اشتراک می‌گذارند. چنین پیاده‌سازی‌ای ضمن کارایی بالا، امکان گرفتن اسنپ‌شات از وضعیت فعلی را به‌سادگی فراهم می‌کند. هر نمونه از کالکشن تغییرناپذیر ذاتاً نخ‌-ایمن است، اما کالکشن‌های تغییرناپذیر را می‌توان در برنامه‌های تک‌نخی نیز به کار برد. به تجربه‌ی من، کالکشن‌های تغییرناپذیر زمانی به‌ویژه مفیدند که کد شما بیشتر تابعی (functional) باشد یا وقتی که باید تعداد زیادی اسنپ‌شات را ذخیره کنید و می‌خواهید تا جای ممکن حافظه را به اشتراک بگذارند.

صف‌ها مشابه پشته‌ها هستند، با این تفاوت که یک ساختار داده‌ای «اول-داخل، اول-خارج» به شمار می‌آیند. کد زیر یک صف تغییرناپذیر خالی می‌سازد، دو آیتم را enqueue می‌کند، آیتم‌ها را پیمایش می‌کند و سپس یک آیتم را dequeue می‌کند:

```csharp
ImmutableQueue<int> queue = ImmutableQueue<int>.Empty;
queue = queue.Enqueue(13);
queue = queue.Enqueue(7);
// ابتدا "13" و سپس "7" را نمایش می‌دهد.
foreach (int item in queue)
    Trace.WriteLine(item);
int nextItem;
queue = queue.Dequeue(out nextItem);
// "13" را نمایش می‌دهد.
Trace.WriteLine(nextItem);
```

### بحث

این دستورعمل دو کالکشن تغییرناپذیر ساده، یعنی پشته و صف را معرفی کرد. همچنین چند فلسفه‌ی طراحی مهم را که درباره‌ی همه‌ی کالکشن‌های تغییرناپذیر صادق‌اند پوشش داد:

   یک نمونه از کالکشن تغییرناپذیر هرگز تغییر نمی‌کند.

 چون هرگز تغییر نمی‌کند، ذاتاً نخ‌-ایمن است.

   وقتی یک متد تغییردهنده را روی یک کالکشن تغییرناپذیر فراخوانی می‌کنید، کالکشنِ جدیدِ تغییریافته بازگردانده می‌شود.

> **هشدار**
> اگرچه خودِ کالکشن‌های تغییرناپذیر نخ‌-ایمن هستند، ارجاع‌ها به کالکشن‌های تغییرناپذیر نخ‌-ایمن نیستند. یک متغیر که به یک کالکشن تغییرناپذیر ارجاع می‌دهد، به همان سازوکارهای همگام‌سازیِ هر متغیر دیگری نیاز دارد (نگاه کنید به فصل ۱۲).

کالکشن‌های تغییرناپذیر برای اشتراک‌گذاری حالت ایده‌آل‌اند. با این حال، به‌عنوان مجرای ارتباطی چندان خوب عمل نمی‌کنند. به‌طور خاص، از یک صف تغییرناپذیر برای ارتباط بین نخ‌ها استفاده نکنید؛ صف‌های تولیدکننده/مصرف‌کننده برای این کار بسیار بهترند.

> **نکته**
> `ImmutableStack<T>` و `ImmutableQueue<T>` در بسته‌ی NuGet با نام `System.Collections.Immutable` در دسترس‌اند.

### همچنین ببینید

   دستورعمل ۹.۶ صف‌های قابل‌تغییر نخ‌-ایمن (مسدودکننده) را پوشش می‌دهد.

   دستورعمل ۹.۷ پشته‌های قابل‌تغییر نخ‌-ایمن (مسدودکننده) را پوشش می‌دهد.

  دستورعمل ۹.۸ صف‌های قابل‌تغییر سازگار با async را پوشش می‌دهد.

   دستورعمل ۹.۱۱ پشته‌های قابل‌تغییر سازگار با async را پوشش می‌دهد.

   دستورعمل ۹.۱۲ صف‌های قابل‌تغییر مسدودکننده/غیرهمزمان را پوشش می‌دهد.




## ۹.۲ فهرست‌های تغییرناپذیر

### مسئله

به یک ساختار داده نیاز دارید که بتوان در آن به‌صورت اندیسی دسترسی داشت، زیاد تغییر نمی‌کند و می‌توان با اطمینان از چندین نخ به آن دسترسی داشت.

### راه‌حل

فهرست یک ساختار داده‌ی عمومی است که می‌تواند برای انواع حالت‌های برنامه کاربرد داشته باشد. فهرست‌های تغییرناپذیر امکان اندیس‌گذاری را می‌دهند، اما باید از ویژگی‌های کارایی آن‌ها آگاه باشید. آن‌ها صرفاً جایگزین مستقیم `List<T>` نیستند.

`ImmutableList<T>` متدهایی مشابه `List<T>` را پشتیبانی می‌کند، همان‌طور که مثال زیر نشان می‌دهد:

```csharp
ImmutableList<int> list = ImmutableList<int>.Empty;
list = list.Insert(0, 13);
list = list.Insert(0, 7);
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
foreach (int item in list)
    Trace.WriteLine(item);
list = list.RemoveAt(1);
```

فهرستِ تغییرناپذیر درونی‌سازی‌اش به شکل یک درخت دودویی است تا نمونه‌های فهرستِ تغییرناپذیر بتوانند حداکثرِ حافظه را با دیگر نمونه‌ها به اشتراک بگذارند. در نتیجه، تفاوت‌های کارایی میان `ImmutableList<T>` و `List<T>` برای برخی عملیات رایج وجود دارد (جدول ۹-۲).

### جدول ۹-۲. تفاوت کارایی فهرست‌های تغییرناپذیر

| عملیات   | `List<T>` | `ImmutableList<T>` |
| :------- | :-------- | :----------------- |
| Add      | به‌طور سرجمع O(1) | O(log N)           |
| Insert   | O(N)      | O(log N)           |
| RemoveAt | O(N)      | O(log N)           |
| Item[index] | O(1)      | O(log N)           |

نکته قابل‌توجه این است که عملیات اندیس‌گذاری در `ImmutableList<T>` برابر `O(log N)` است، نه `O(1)` همان‌گونه که شاید انتظار داشته باشید. اگر در کد موجود، `List<T>` را با `ImmutableList<T>` جایگزین می‌کنید، لازم است در نظر بگیرید الگوریتم‌هایتان چگونه به آیتم‌های کالکشن دسترسی می‌یابند.

این یعنی تا حد ممکن باید به‌جای `for` از `foreach` استفاده کنید. یک حلقه‌ی `foreach` روی `ImmutableList<T>` در زمان `O(N)` اجرا می‌شود، در حالی که حلقه‌ی `for` روی همان کالکشن در زمان `O(N * log N)` اجرا می‌شود:

```csharp
// بهترین روش تکرار روی ImmutableList<T>.
foreach (var item in list)
    Trace.WriteLine(item);
// این هم کار می‌کند، اما بسیار کندتر خواهد بود.
for (int i = 0; i != list.Count; ++i)
    Trace.WriteLine(list[i]);
```

### بحث

`ImmutableList<T>` یک ساختار داده‌ی عمومیِ خوب است، اما به‌دلیل تفاوت‌های کارایی، نمی‌توانید بی‌محابا همه‌ی استفاده‌های `List<T>` خود را با آن جایگزین کنید. `List<T>` معمولاً به‌طور پیش‌فرض به کار می‌رود—یعنی تا زمانی که به کالکشن دیگری نیاز نداشته باشید، از آن استفاده می‌کنید. `ImmutableList<T>` این‌قدر هم همه‌جا حاضر نیست؛ باید سایر کالکشن‌های تغییرناپذیر را با دقت بسنجید و آن را انتخاب کنید که بیشترین معنا را برای وضعیت شما دارد.

> **نکته**
> `ImmutableList<T>` در بسته‌ی NuGet با نام `System.Collections.Immutable` موجود است.

### همچنین ببینید

   دستورعمل ۹.۱ پشته‌ها و صف‌های تغییرناپذیر را پوشش می‌دهد که شبیه فهرست‌اند، اما فقط اجازه‌ی دسترسی به برخی عناصر را می‌دهند.

   مستندات MSDN درباره‌ی `ImmutableList<T>.Builder` روشی کارا برای پُر کردن یک فهرستِ تغییرناپذیر را پوشش می‌دهد.

---

## ۹.۳ مجموعه‌های تغییرناپذیر

### مسئله

به یک ساختار داده نیاز دارید که لازم نیست مقادیر تکراری را نگه دارد، زیاد تغییر نمی‌کند و می‌توان با اطمینان از چندین نخ به آن دسترسی داشت.

برای مثال، نمایه‌ای از واژه‌های یک فایل، مورد استفاده‌ی خوبی برای یک مجموعه (Set) است.

### راه‌حل

دو نوع مجموعه‌ی تغییرناپذیر وجود دارد: `ImmutableHashSet<T>` که مجموعه‌ای از آیتم‌های یکتا است، و `ImmutableSortedSet<T>` که مجموعه‌ای مرتب از آیتم‌های یکتا است. هر دو نوع رابطی مشابه دارند:

```csharp
ImmutableHashSet<int> hashSet = ImmutableHashSet<int>.Empty;
hashSet = hashSet.Add(13);
hashSet = hashSet.Add(7);
// "7" و "13" را در ترتیبی غیرقابل پیش‌بینی نمایش می‌دهد.
foreach (int item in hashSet)
    Trace.WriteLine(item);
hashSet = hashSet.Remove(7);
```

تنها مجموعه‌ی مرتب اجازه‌ی اندیس‌گذاری مانند فهرست را می‌دهد:

```csharp
ImmutableSortedSet<int> sortedSet =
    ImmutableSortedSet<int>.Empty;
sortedSet = sortedSet.Add(13);
sortedSet = sortedSet.Add(7);
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
foreach (int item in sortedSet)
    Trace.WriteLine(item);
int smallestItem = sortedSet[0];
// smallestItem == 7
sortedSet = sortedSet.Remove(7);
```

مجموعه‌های نامرتب و مرتب کارایی مشابهی دارند (جدول ۹-۳).

### جدول ۹-۳. کارایی مجموعه‌های تغییرناپذیر

| عملیات  | `ImmutableHashSet<T>` | `ImmutableSortedSet<T>` |
| :------ | :-------------------- | :---------------------- |
| Add     | O(log N)              | O(log N)                |
| Remove  | O(log N)              | O(log N)                |
| Item[index] | n/a                   | O(log N)                |

با این حال، توصیه می‌کنم از مجموعه‌ی نامرتب استفاده کنید مگر این‌که بدانید نیاز به مرتب بودن دارد. بسیاری از نوع‌ها فقط برابری پایه را پشتیبانی می‌کنند و نه مقایسه‌ی کامل، بنابراین مجموعه‌ی نامرتب را می‌توان برای انواع بسیار بیشتری نسبت به مجموعه‌ی مرتب به کار برد.

نکته‌ی مهم درباره‌ی مجموعه‌ی مرتب این است که اندیس‌گذاری آن `O(log N)` است، نه `O(1)`، درست مانند `ImmutableList<T>` که در دستورعمل ۹.۲ پوشش داده شد. این یعنی همان هشدار در اینجا نیز صادق است: تا حد امکان باید به‌جای `for` از `foreach` هنگام کار با `ImmutableSortedSet<T>` استفاده کنید.

### بحث

مجموعه‌های تغییرناپذیر ساختارهای داده‌ی مفیدی هستند، اما پُر کردن یک مجموعه‌ی تغییرناپذیر بزرگ می‌تواند کند باشد. اکثر کالکشن‌های تغییرناپذیر سازنده‌های ویژه‌ای دارند که می‌توان از آن‌ها برای ساخت سریع آن‌ها به‌صورت قابل‌تغییر استفاده کرد و سپس آن را به یک کالکشن تغییرناپذیر تبدیل نمود. این موضوع درباره‌ی بسیاری از کالکشن‌های تغییرناپذیر صادق است، اما به تجربه‌ی من، برای مجموعه‌های تغییرناپذیر بیشترین فایده را دارد.

> **نکته**
> `ImmutableHashSet<T>` و `ImmutableSortedSet<T>` در بسته‌ی NuGet با نام `System.Collections.Immutable` موجودند.

### همچنین ببینید

   دستورعمل ۹.۷ کیف‌های (bag) قابل‌تغییر نخ‌-ایمن را که مشابه مجموعه‌ها هستند پوشش می‌دهد.

   دستورعمل ۹.۱۱ کیف‌های قابل‌تغییر سازگار با async را پوشش می‌دهد.

   مستندات MSDN درباره‌ی `ImmutableHashSet<T>.Builder` روشی کارا برای پُر کردن یک مجموعه‌ی هشِ تغییرناپذیر را پوشش می‌دهد.

   مستندات MSDN درباره‌ی `ImmutableSortedSet<T>.Builder` روشی کارا برای پُر کردن یک مجموعه‌ی مرتبِ تغییرناپذیر را پوشش می‌دهد.

---

## ۹.۴ دیکشنری‌های تغییرناپذیر

### مسئله

به یک کالکشن کلید/مقدار نیاز دارید که زیاد تغییر نکند و بتوان با اطمینان از چندین نخ به آن دسترسی داشت. برای مثال، ممکن است بخواهید داده‌های مرجع را در یک کالکشن lookup نگه دارید؛ داده‌های مرجع به‌ندرت تغییر می‌کنند اما باید برای نخ‌های مختلف در دسترس باشند.

### راه‌حل

دو نوع دیکشنری تغییرناپذیر وجود دارد: `ImmutableDictionary<TKey, TValue>` و `ImmutableSortedDictionary<TKey, TValue>`. همان‌طور که از نامشان برمی‌آید، در حالی که آیتم‌ها در `ImmutableDictionary` ترتیب غیرقابل پیش‌بینی دارند، `ImmutableSortedDictionary` تضمین می‌کند که عناصرش مرتب هستند. هر دوی این انواع کالکشن اعضای بسیار مشابهی دارند:

```csharp
ImmutableDictionary<int, string> dictionary =
    ImmutableDictionary<int, string>.Empty;
dictionary = dictionary.Add(10, "Ten");
dictionary = dictionary.Add(21, "Twenty-One");
dictionary = dictionary.SetItem(10, "Diez");
// "10Diez" و "21Twenty-One" را در ترتیبی غیرقابل پیش‌بینی نمایش می‌دهد.
foreach (KeyValuePair<int, string> item in dictionary)
    Trace.WriteLine(item.Key + item.Value);
string ten = dictionary[10];
// ten == "Diez"
dictionary = dictionary.Remove(21);
```

به استفاده از `SetItem` توجه کنید. در یک دیکشنری قابل‌تغییر، می‌توانید چیزی شبیه `dictionary[key] = item` بنویسید، اما دیکشنری‌های تغییرناپذیر باید دیکشنریِ تغییر‌یافته‌ی جدید را برگردانند، بنابراین از متد `SetItem` استفاده می‌کنند:

```csharp
ImmutableSortedDictionary<int, string> sortedDictionary =
    ImmutableSortedDictionary<int, string>.Empty;
sortedDictionary = sortedDictionary.Add(10, "Ten");
sortedDictionary = sortedDictionary.Add(21, "Twenty-One");
sortedDictionary = sortedDictionary.SetItem(10, "Diez");
// ابتدا "10Diez" و سپس "21Twenty-One" را نمایش می‌دهد.
foreach (KeyValuePair<int, string> item in sortedDictionary)
    Trace.WriteLine(item.Key + item.Value);
string ten = sortedDictionary[10];
// ten == "Diez"
sortedDictionary = sortedDictionary.Remove(21);
```

دیکشنری‌های نامرتب و مرتب کارایی مشابهی دارند، اما توصیه می‌کنم مگر این‌که نیاز داشته باشید عناصر مرتب باشند، از دیکشنری نامرتب استفاده کنید (جدول ۹-۴ را ببینید). دیکشنری‌های نامرتب کمی سریع‌تر هم هستند. علاوه بر این، دیکشنری‌های نامرتب را می‌توان با هر نوع کلیدی به کار برد، در حالی که دیکشنری‌های مرتب نیاز دارند کلیدها کاملاً قابل مقایسه باشند.

### جدول ۹-۴. کارایی دیکشنری‌های تغییرناپذیر

| عملیات   | `ImmutableDictionary<TK,TV>` | `ImmutableSortedDictionary<TK,TV>` |
| :------- | :--------------------------- | :--------------------------------- |
| Add      | O(log N)                     | O(log N)                           |
| SetItem  | O(log N)                     | O(log N)                           |
| Item[key] | O(log N)                     | O(log N)                           |
| Remove   | O(log N)                     | O(log N)                           |

### بحث

به تجربه‌ی من، دیکشنری‌ها هنگام کار با حالت برنامه ابزاری رایج و مفیدند. می‌توان آن‌ها را در هر سناریوی کلید/مقدار یا lookup استفاده کرد.

مانند سایر کالکشن‌های تغییرناپذیر، دیکشنری‌های تغییرناپذیر برای ساخت کارا در صورت داشتن عناصر زیاد، سازوکار Builder دارند. برای مثال، اگر داده‌های مرجع اولیه‌تان را در ابتدای اجرا بارگذاری می‌کنید، باید از Builder برای ساخت دیکشنری تغییرناپذیر اولیه استفاده کنید. از سوی دیگر، اگر داده‌های مرجع به‌تدریج در طول اجرای برنامه ساخته می‌شوند، استفاده از متد `Add` روی دیکشنری تغییرناپذیر معمولاً قابل‌قبول است.

> **نکته**
> `ImmutableDictionary<TK, TV>` و `ImmutableSortedDictionary<TK, TV>` در بسته‌ی NuGet با نام `System.Collections.Immutable` موجودند.

### همچنین ببینید

   دستورعمل ۹.۵ دیکشنری‌های قابل‌تغییر نخ‌-ایمن را پوشش می‌دهد.

   مستندات MSDN درباره‌ی `ImmutableDictionary<TK`





## ۹.۶ صف‌های مسدودکننده (Blocking Queues)

### مسئله

به یک مجرا نیاز دارید تا پیام‌ها یا داده‌ها را از یک نخ به نخ دیگر منتقل کنید. برای مثال، یک نخ می‌تواند داده را بارگذاری کند و هم‌زمان هنگام بارگذاری آن را در مجرا هل دهد؛ در همین حال، نخ‌های دیگری در سمت دریافت مجرا داده را دریافت و پردازش می‌کنند.

### راه‌حل

نوع `BlockingCollection<T>` در .NET دقیقاً برای چنین مجرایی طراحی شده است. به‌طور پیش‌فرض، `BlockingCollection<T>` یک صف مسدودکننده با رفتار «اول-داخل، اول-خارج» است.

یک صف مسدودکننده باید بین چند نخ به اشتراک گذاشته شود و معمولاً به‌صورت یک فیلد خصوصیِ فقط‌خواندنی تعریف می‌شود:

```csharp
private readonly BlockingCollection<int> _blockingQueue =
    new BlockingCollection<int>();
```

معمولاً یک نخ یا آیتم‌ها را به کالکشن اضافه می‌کند یا از آن حذف می‌کند، اما نه هر دو. نخ‌هایی که آیتم اضافه می‌کنند «تولیدکننده» و نخ‌هایی که آیتم حذف می‌کنند «مصرف‌کننده» نامیده می‌شوند.

نخ‌های تولیدکننده می‌توانند با فراخوانی `Add` آیتم‌ها را اضافه کنند و وقتی کار نخ تولیدکننده تمام شد (همه‌ی آیتم‌ها اضافه شدند)، می‌تواند با فراخوانی `CompleteAdding`، کالکشن را خاتمه دهد. این کار به کالکشن اطلاع می‌دهد که آیتم دیگری به آن اضافه نخواهد شد و کالکشن می‌تواند به مصرف‌کنندگان اعلام کند که آیتم دیگری وجود نخواهد داشت.

در اینجا یک مثال ساده از تولیدکننده‌ای که دو آیتم اضافه می‌کند و سپس کالکشن را کامل می‌کند:

```csharp
_blockingQueue.Add(7);
_blockingQueue.Add(13);
_blockingQueue.CompleteAdding();
```

نخ‌های مصرف‌کننده معمولاً در یک حلقه اجرا می‌شوند، منتظر آیتم بعدی می‌مانند و سپس آن را پردازش می‌کنند. اگر کد تولیدکننده را در نخ جداگانه‌ای قرار دهید (مثلاً با `Task.Run`)، می‌توانید آیتم‌ها را این‌گونه مصرف کنید:

```csharp
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
foreach (int item in _blockingQueue.GetConsumingEnumerable())
    Trace.WriteLine(item);
```

اگر بخواهید چند مصرف‌کننده داشته باشید، می‌توان `GetConsumingEnumerable` را به‌طور هم‌زمان از چند نخ فراخوانی کرد. با این حال، هر آیتم فقط به یکی از آن نخ‌ها تحویل داده می‌شود. وقتی کالکشن کامل شود، `enumerable` نیز کامل می‌شود.

### بحث

در مثال‌های بالا، برای نخ‌های مصرف‌کننده از `GetConsumingEnumerable` استفاده شده است؛ این رایج‌ترین سناریو است. با این حال، عضوی به نام `Take` نیز وجود دارد که به مصرف‌کننده اجازه می‌دهد فقط یک آیتم را مصرف کند، به‌جای اجرای حلقه برای مصرف همه‌ی آیتم‌ها.

وقتی از چنین مجراهایی استفاده می‌کنید، باید در نظر داشته باشید اگر تولیدکننده‌ها سریع‌تر از مصرف‌کننده‌ها عمل کنند چه می‌شود. اگر آیتم‌ها را سریع‌تر از توان مصرف تولید می‌کنید، ممکن است لازم باشد صف خود را محدودسازی (throttle) کنید.

صف‌های مسدودکننده زمانی عالی‌اند که یک نخ جداگانه (مانند یک نخ از `ThreadPool`) نقش تولیدکننده یا مصرف‌کننده را بازی کند. وقتی می‌خواهید به مجرا به‌صورت غیرهمزمان دسترسی داشته باشید—برای مثال اگر نخ UI می‌خواهد مصرف‌کننده باشد—گزینه‌ی مناسبی نیستند. دستورعمل ۹.۸ صف‌های غیرهمزمان را پوشش می‌دهد.

> **نکته**
> هرگاه چنین مجرایی را وارد برنامه‌تان می‌کنید، به استفاده از کتابخانه‌ی TPL Dataflow فکر کنید. در بسیاری از مواقع، استفاده از TPL Dataflow ساده‌تر از ساختن مجراهای اختصاصی و نخ‌های پس‌زمینه است.
> `BufferBlock<T>` در TPL Dataflow می‌تواند مانند یک صف مسدودکننده عمل کند و TPL Dataflow امکان ساخت خط لوله یا شبکه‌ای برای پردازش را فراهم می‌کند. با این حال، در بسیاری از موارد ساده، صف‌های مسدودکننده‌ی معمولی مانند `BlockingCollection<T>` انتخاب طراحی مناسبی هستند.
> همچنین می‌توانید از نوع `AsyncProducerConsumerQueue<T>` در کتابخانه‌ی AsyncEx استفاده کنید که می‌تواند مانند یک صف مسدودکننده عمل کند.

### همچنین ببینید

   دستورعمل ۹.۷ پشته‌ها و کیف‌های مسدودکننده را پوشش می‌دهد، اگر مجرایی مشابه بدون معنای «اول-داخل، اول-خارج» می‌خواهید.

   دستورعمل ۹.۸ صف‌هایی را پوشش می‌دهد که API غیرهمزمان دارند نه مسدودکننده.

   دستورعمل ۹.۱۲ صف‌هایی را پوشش می‌دهد که هم API غیرهمزمان و هم مسدودکننده دارند.

   دستورعمل ۹.۹ صف‌هایی را پوشش می‌دهد که تعداد آیتم‌های خود را محدودسازی می‌کنند.

---

## ۹.۷ پشته‌ها و کیف‌های مسدودکننده

### مسئله

به مجرایی برای انتقال پیام‌ها یا داده‌ها از یک نخ به نخ دیگر نیاز دارید، اما نمی‌خواهید (یا نیازی ندارید) که این مجرا معنای «اول-داخل، اول-خارج» داشته باشد.

### راه‌حل

نوع `BlockingCollection<T>` در .NET به‌طور پیش‌فرض مانند یک صف مسدودکننده عمل می‌کند، اما می‌تواند مانند هر نوع کالکشن تولیدکننده/مصرف‌کننده‌ای نیز رفتار کند. در واقع، این نوع یک روکش روی یک کالکشن نخ‌-ایمن است که `IProducerConsumerCollection<T>` را پیاده‌سازی می‌کند.

بنابراین، می‌توانید `BlockingCollection<T>` را با معنای «آخر-داخل، اول-خارج» (پشته) یا بدون ترتیب (کیف/bag) بسازید:

```csharp
BlockingCollection<int> _blockingStack =
    new BlockingCollection<int>(
        new ConcurrentStack<int>());
BlockingCollection<int> _blockingBag =
    new BlockingCollection<int>(
        new ConcurrentBag<int>());
```

مهم است به خاطر داشته باشید که اکنون پیرامون ترتیب آیتم‌ها شرایط رقابتی (race conditions) وجود دارد. اگر اجازه دهید همان کد تولیدکننده قبل از هر کد مصرف‌کننده‌ای اجرا شود و سپس کد مصرف‌کننده پس از کد تولیدکننده اجرا شود، ترتیب آیتم‌ها دقیقاً مانند یک پشته خواهد بود:

```csharp
// کد تولیدکننده
_blockingStack.Add(7);
_blockingStack.Add(13);
_blockingStack.CompleteAdding();

// کد مصرف‌کننده
// ابتدا "13" و سپس "7" را نمایش می‌دهد.
foreach (int item in _blockingStack.GetConsumingEnumerable())
    Trace.WriteLine(item);
```

وقتی کد تولیدکننده و مصرف‌کننده روی نخ‌های متفاوتی هستند (که حالت معمول است)، مصرف‌کننده همیشه «جدیدترین آیتم اضافه‌شده» را بعدی دریافت می‌کند. برای مثال، تولیدکننده 7 را اضافه می‌کند، مصرف‌کننده 7 را برمی‌دارد، تولیدکننده 13 را اضافه می‌کند، و مصرف‌کننده 13 را برمی‌دارد. مصرف‌کننده برای برگرداندن اولین آیتم منتظر `CompleteAdding` نمی‌ماند.

### بحث

همان ملاحظات محدودسازی که برای صف‌های مسدودکننده وجود دارد، برای پشته‌ها و کیف‌های مسدودکننده نیز صادق است. اگر تولیدکننده‌ها سریع‌تر از مصرف‌کننده‌ها هستند و باید مصرف حافظه‌ی پشته/کیف مسدودکننده‌ی خود را محدود کنید، می‌توانید طبق دستورعمل ۹.۹ از محدودسازی استفاده کنید.

در این دستورعمل برای کد مصرف‌کننده از `GetConsumingEnumerable` استفاده شده است؛ این رایج‌ترین سناریو است. عضوی نیز به نام `Take` وجود دارد که به مصرف‌کننده اجازه می‌دهد فقط یک آیتم را مصرف کند، به‌جای اجرای حلقه برای مصرف همه‌ی آیتم‌ها.

اگر می‌خواهید به‌جای مسدود کردن، به پشته‌ها یا کیف‌های مشترک به‌صورت غیرهمزمان دسترسی داشته باشید (برای مثال، وقتی نخ UI نقش مصرف‌کننده را دارد)، به دستورعمل ۹.۱۱ مراجعه کنید.

### همچنین ببینید

   دستورعمل ۹.۶ صف‌های مسدودکننده را پوشش می‌دهد که بسیار رایج‌تر از پشته‌ها یا کیف‌های مسدودکننده‌اند.

   دستورعمل ۹.۱۱ پشته‌ها و کیف‌های غیرهمزمان را پوشش می‌دهد.

---

## ۹.۸ صف‌های غیرهمزمان

### مسئله

به مجرایی نیاز دارید تا پیام‌ها یا داده‌ها را از بخشی از کد به بخش دیگر به‌صورت «اول-داخل، اول-خارج» منتقل کند، بدون اینکه نخ‌ها را مسدود کند. برای مثال، بخشی از کد ممکن است در حال بارگذاری داده باشد و در حین بارگذاری آن‌ها را در مجرا قرار دهد؛ در همین حال، نخ UI داده‌ها را دریافت و نمایش می‌دهد.

### راه‌حل

آنچه نیاز دارید، صفی با API غیرهمزمان است. چنین نوعی در هستهٔ چارچوب .NET وجود ندارد، اما چند گزینه از طریق NuGet در دسترس‌اند.

گزینهٔ اول استفاده از `Channels` است. `Channels` کتابخانه‌ای مدرن برای مجموعه‌های تولیدکننده/مصرف‌کنندهٔ غیرهمزمان است که روی عملکرد بالا در سناریوهای با حجم زیاد تمرکز دارد. تولیدکننده‌ها معمولاً از `WriteAsync` برای نوشتن آیتم‌ها در یک channel استفاده می‌کنند و وقتی همگی تولیدشان تمام شد، یکی از آن‌ها با فراخوانی `Complete` به channel اطلاع می‌دهد که در آینده آیتم بیشتری نخواهد آمد، مانند این:

```csharp
Channel<int> queue = Channel.CreateUnbounded<int>();

// کد تولیدکننده
ChannelWriter<int> writer = queue.Writer;
await writer.WriteAsync(7);
await writer.WriteAsync(13);
writer.Complete();

// کد مصرف‌کننده
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
ChannelReader<int> reader = queue.Reader;
await foreach (int value in reader.ReadAllAsync())
    Trace.WriteLine(value);
```

این کد مصرف‌کنندهٔ طبیعی‌تر از جریان‌های غیرهمزمان استفاده می‌کند؛ برای اطلاعات بیشتر فصل ۳ را ببینید. در زمان نگارش، جریان‌های غیرهمزمان فقط در جدیدترین پلتفرم‌های .NET در دسترس‌اند؛ پلتفرم‌های قدیمی‌تر می‌توانند از الگوی زیر استفاده کنند:

```csharp
// کد مصرف‌کننده (پلتفرم‌های قدیمی‌تر)
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
ChannelReader<int> reader = queue.Reader;
while (await reader.WaitToReadAsync())
    while (reader.TryRead(out int value))
        Trace.WriteLine(value);
```

به حلقهٔ دوگانهٔ `while` در کد مصرف‌کننده برای پلتفرم‌های قدیمی‌تر توجه کنید؛ این طبیعی است. `WaitToReadAsync` به‌صورت غیرهمزمان منتظر می‌ماند تا یا آیتمی در دسترس شود یا `channel` علامت‌گذاری شده باشد که کامل شده است؛ وقتی آیتمی برای خواندن موجود باشد، `true` برمی‌گرداند. `TryRead` تلاش می‌کند یک آیتم را بلافاصله و همگام بخواند و اگر آیتمی خوانده شد `true` برمی‌گرداند. اگر `TryRead` مقدار `false` برگرداند، ممکن است به این دلیل باشد که الان هیچ آیتمی موجود نیست یا اینکه `channel` علامت‌گذاری شده که کامل شده و هرگز آیتم دیگری نخواهد داشت. بنابراین وقتی `TryRead` `false` برمی‌گرداند، حلقهٔ داخلی خارج می‌شود و مصرف‌کننده دوباره `WaitToReadAsync` را فراخوانی می‌کند که در صورت تکمیل `channel` مقدار `false` برمی‌گرداند.

گزینهٔ دیگر برای صف تولیدکننده/مصرف‌کننده استفاده از `BufferBlock<T>` از کتابخانهٔ TPL Dataflow است. `BufferBlock<T>` خیلی شبیه `channel` است. مثال زیر نشان می‌دهد چگونه یک `BufferBlock<T>` اعلام کنید، کد تولیدکننده چگونه است و کد مصرف‌کننده چگونه است:

```csharp
var _asyncQueue = new BufferBlock<int>();

// کد تولیدکننده
await _asyncQueue.SendAsync(7);
await _asyncQueue.SendAsync(13);
_asyncQueue.Complete();

// کد مصرف‌کننده
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
while (await _asyncQueue.OutputAvailableAsync())
    Trace.WriteLine(await _asyncQueue.ReceiveAsync());
```

کد مثال از `OutputAvailableAsync` استفاده می‌کند که در واقع تنها وقتی مفید است که یک مصرف‌کنندهٔ واحد داشته باشید. اگر چند مصرف‌کننده داشته باشید، ممکن است `OutputAvailableAsync` برای بیش از یک مصرف‌کننده `true` برگردد در حالی که فقط یک آیتم وجود دارد. اگر صف تکمیل شده باشد، `ReceiveAsync` استثنای `InvalidOperationException` پرتاب خواهد کرد. بنابراین اگر چند مصرف‌کننده دارید، معمولاً کد مصرف‌کننده شبیه نمونهٔ زیر است:

```csharp
while (true)
{
    int item;
    try
    {
        item = await _asyncQueue.ReceiveAsync();
    }
    catch (InvalidOperationException)
    {
        break;
    }
    Trace.WriteLine(item);
}
```

همچنین می‌توانید از نوع `AsyncProducerConsumerQueue<T>` از کتابخانهٔ Nito.AsyncEx استفاده کنید. API آن شبیه اما دقیقاً همان `BufferBlock<T>` نیست:

```csharp
var _asyncQueue = new AsyncProducerConsumerQueue<int>();

// کد تولیدکننده
await _asyncQueue.EnqueueAsync(7);
await _asyncQueue.EnqueueAsync(13);
_asyncQueue.CompleteAdding();

// کد مصرف‌کننده
// ابتدا "7" و سپس "13" را نمایش می‌دهد.
while (await _asyncQueue.OutputAvailableAsync())
    Trace.WriteLine(await _asyncQueue.DequeueAsync());
```

این کد مصرف‌کننده نیز از `OutputAvailableAsync` استفاده می‌کند و همان مشکلات `BufferBlock<T>` را دارد. اگر چند مصرف‌کننده داشته باشید، معمولاً کد مصرف‌کننده شبیه نمونهٔ زیر است:

```csharp
while (true)
{
    int item;
    try
    {
        item = await _asyncQueue.DequeueAsync();
    }
    catch (InvalidOperationException)
    {
        break;
    }
    Trace.WriteLine(item);
}
```

### بحث

من توصیه می‌کنم هر زمان ممکن است از `Channels` برای صف‌های تولیدکننده/مصرف‌کنندهٔ غیرهمزمان استفاده کنید. آن‌ها گزینه‌های نمونه‌برداری متعددی علاوه بر محدودسازی دارند و بسیار بهینه شده‌اند. با این حال، اگر منطق برنامهٔ شما را می‌توان به‌صورت یک «خط لوله» بیان کرد که داده‌ها در آن جریان دارند، آنگاه TPL Dataflow ممکن است مناسب‌تر باشد. گزینهٔ نهایی `AsyncProducerConsumerQueue<T>` است که ممکن است اگر برنامهٔ شما از انواع دیگر AsyncEx استفاده می‌کند معقول باشد.

> **نکته**
> `Channels` در بستهٔ NuGet با نام `System.Threading.Channels` موجود است. نوع `BufferBlock<T>` در بستهٔ `System.Threading.Tasks.Dataflow` قرار دارد. نوع `AsyncProducerConsumerQueue<T>` در بستهٔ `Nito.AsyncEx` در دسترس است.

### همچنین ببینید

   دستورعمل ۹.۶ صف‌های تولیدکننده/مصرف‌کننده با معنای مسدودکننده را پوشش می‌دهد، نه معنای غیرهمزمان.

   دستورعمل ۹.۱۲ صف‌هایی را پوشش می‌دهد که هر دو معنای مسدودکننده و غیرهمزمان را دارند.

   دستورعمل ۹.۷ پشته‌ها و کیف‌های غیرهمزمان را پوشش می‌دهد اگر مجرایی مشابه بدون معنای «اول-داخل، اول-خارج» می‌خواهید.




## ۹.۹ محدودسازی (Throttling) صف‌ها

### مسئله

شما یک صف تولیدکننده/مصرف‌کننده دارید و ممکن است تولیدکننده‌ها سریع‌تر از مصرف‌کننده‌ها اجرا شوند که این باعث استفادهٔ حافظهٔ نامطلوب می‌شود. همچنین می‌خواهید همهٔ آیتم‌های صف را نگه دارید، پس نیاز به روشی برای محدودسازی تولیدکننده‌ها دارید.

### راه‌حل

وقتی از صف‌های تولیدکننده/مصرف‌کننده استفاده می‌کنید، باید در نظر بگیرید اگر تولیدکننده‌ها سریع‌تر از مصرف‌کننده‌ها اجرا شوند چه می‌شود، مگر اینکه مطمئن باشید مصرف‌کننده‌ها همیشه سریع‌تر خواهند بود. اگر آیتم‌ها را سریع‌تر از توان مصرف تولید می‌کنید، ممکن است نیاز باشد صف را محدودسازی (throttle) کنید. می‌توانید صف را با تعیین حداکثر تعداد عناصر محدود کنید. وقتی صف «پر» شد، به تولیدکننده‌ها فشار بازگشتی (backpressure) وارد می‌کند و آن‌ها را مسدود می‌کند تا وقتی فضای بیشتری در صف ایجاد شود.

کانال‌ها را می‌توان با ایجاد یک `channel` محدود به‌جای `channel` نامحدود محدودسازی کرد. از آن‌جا که کانال‌ها غیرهمزمان هستند، تولیدکننده‌ها به‌صورت غیرهمزمان محدود خواهند شد:

```csharp
Channel<int> queue = Channel.CreateBounded<int>(1);
ChannelWriter<int> writer = queue.Writer;
// این Write بلافاصله تکمیل می‌شود.
await writer.WriteAsync(7);
// این Write به‌صورت غیرهمزمان منتظر می‌ماند تا مقدار 7 برداشته شود
// سپس مقدار 13 را در صف قرار می‌دهد.
await writer.WriteAsync(13);
writer.Complete();
```

`BufferBlock<T>` پشتیبانی داخلی از محدودسازی دارد که در دستورعمل 5.4 با جزئیات بررسی شده است. با بلوک‌های Dataflow، گزینهٔ `BoundedCapacity` را تنظیم می‌کنید:

```csharp
var queue = new BufferBlock<int>(
    new DataflowBlockOptions { BoundedCapacity = 1 });
// این Send بلافاصله تکمیل می‌شود.
await queue.SendAsync(7);
// این Send به‌صورت غیرهمزمان منتظر می‌ماند تا مقدار 7 برداشته شود
// سپس مقدار 13 را در صف قرار می‌دهد.
await queue.SendAsync(13);
queue.Complete();
```

در قطعهٔ کد بالا تولیدکننده از API غیرهمزمان `SendAsync` استفاده می‌کند؛ همین رویکرد برای API همگام `Post` نیز کار می‌کند.

نوع `AsyncProducerConsumerQueue<T>` در AsyncEx نیز از محدودسازی پشتیبانی می‌کند. کافی است صف را با مقدار مناسب بسازید:

```csharp
var queue = new AsyncProducerConsumerQueue<int>(maxCount: 1);
// این Enqueue بلافاصله تکمیل می‌شود.
await queue.EnqueueAsync(7);
// این Enqueue به‌صورت غیرهمزمان منتظر می‌ماند تا مقدار 7 برداشته شود
// سپس مقدار 13 را در صف قرار می‌دهد.
await queue.EnqueueAsync(13);
queue.CompleteAdding();
```

صف‌های تولیدکننده/مصرف‌کنندهٔ مسدودکننده نیز از محدودسازی پشتیبانی می‌کنند. می‌توانید از `BlockingCollection<T>` برای محدود کردن تعداد آیتم‌ها با ارسال مقدار مناسب هنگام ساخت آن استفاده کنید:

```csharp
var queue = new BlockingCollection<int>(boundedCapacity: 1);
// این Add بلافاصله تکمیل می‌شود.
queue.Add(7);
// این Add منتظر می‌ماند تا مقدار 7 برداشته شود قبل از این‌که 13 را اضافه کند.
queue.Add(13);
queue.CompleteAdding();
```

### بحث

هر زمان که تولیدکننده‌ها ممکن است سریع‌تر از مصرف‌کننده‌ها اجرا شوند، محدودسازی ضروری است. یک سناریوی مهم این است که بررسی کنید آیا ممکن است تولیدکننده‌ها در سخت‌افزار دیگر (مثلاً سرور یا نمونهٔ ابری) سریع‌تر از مصرف‌کننده‌ها اجرا شوند یا خیر. معمولاً مقداری محدودسازی لازم است تا اطمینان حاصل شود برنامهٔ شما روی سخت‌افزار یا نمونه‌های ابری آینده، که معمولاً از ماشین‌های توسعه‌دهنده محدودترند، خوب اجرا می‌شود.

محدودسازی فشار بازگشتی روی تولیدکننده‌ها ایجاد می‌کند و آن‌ها را کند می‌کند تا مصرف‌کننده‌ها بتوانند همهٔ آیتم‌ها را پردازش کنند، بدون این‌که فشار حافظهٔ نامناسبی ایجاد شود. اگر نیازی به پردازش هر آیتم ندارید، می‌توانید به‌جای محدودسازی از نمونه‌برداری (sampling) استفاده کنید. دستورعمل 9.10 صف‌های تولیدکننده/مصرف‌کنندهٔ نمونه‌برداری شده را پوشش می‌دهد.

> **نکته**
> `Channels` در بستهٔ NuGet با نام `System.Threading.Channels` موجود است. نوع `BufferBlock<T>` در بستهٔ `System.Threading.Tasks.Dataflow` قرار دارد. نوع `AsyncProducerConsumerQueue<T>` در بستهٔ `Nito.AsyncEx` در دسترس است.

### همچنین ببینید

   دستورعمل 9.8 استفادهٔ پایه از صف‌های تولیدکننده/مصرف‌کنندهٔ غیرهمزمان را پوشش می‌دهد.

   دستورعمل 9.6 استفادهٔ پایه از صف‌های تولیدکننده/مصرف‌کنندهٔ همگام (مسدودکننده) را پوشش می‌دهد.

   دستورعمل 9.10 صف‌های تولیدکننده/مصرف‌کنندهٔ نمونه‌برداری شده را به‌عنوان جایگزینی برای محدودسازی پوشش می‌دهد.

---

## ۹.۱۰ صف‌های نمونه‌برداری

### مسئله

شما یک صف تولیدکننده/مصرف‌کننده دارید، اما ممکن است تولیدکننده‌ها سریع‌تر از مصرف‌کننده‌ها اجرا شوند و این باعث مصرف حافظهٔ نامطلوب شود. شما نیازی به نگهداری همهٔ آیتم‌های صف ندارید؛ نیاز دارید آیتم‌ها را فیلتر کنید تا تولیدکننده‌های سریع فقط آیتم‌های مهم را نیاز به پردازش داشته باشند.

### راه‌حل

کانال‌ها (`Channels`) ساده‌ترین راه برای اعمال نمونه‌برداری روی آیتم‌های ورودی هستند. یک مثال رایج این است که همیشه جدیدترین `n` آیتم را نگه دارید و آیتم‌های قدیمی‌تر را وقتی صف پر شد دور بریزید:

```csharp
Channel<int> queue = Channel.CreateBounded<int>(
    new BoundedChannelOptions(1)
    {
        FullMode = BoundedChannelFullMode.DropOldest,
    });
ChannelWriter<int> writer = queue.Writer;
// این Write بلافاصله تکمیل می‌شود.
await writer.WriteAsync(7);
// این Write نیز بلافاصله تکمیل می‌شود.
// مقدار 7 دور ریخته می‌شود مگر اینکه مصرف‌کننده قبلاً آن را خوانده باشد.
await writer.WriteAsync(13);
```

این روش ساده‌ای برای کنترل جریان ورودی است تا مصرف‌کننده‌ها با سیل داده مواجه نشوند.

گزینه‌های دیگری برای `BoundedChannelFullMode` نیز وجود دارد. مثلاً اگر می‌خواهید آیتم‌های قدیمی حفظ شوند، می‌توانید آیتم‌های جدید را وقتی کانال پر است کنار بگذارید:

```csharp
Channel<int> queue = Channel.CreateBounded<int>(
    new BoundedChannelOptions(1)
    {
        FullMode = BoundedChannelFullMode.DropWrite,
    });
ChannelWriter<int> writer = queue.Writer;
// این Write بلافاصله تکمیل می‌شود.
await writer.WriteAsync(7);
// این Write نیز بلافاصله تکمیل می‌شود.
// مقدار 13 دور ریخته می‌شود مگر اینکه مصرف‌کننده قبلاً مقدار 7 را خوانده باشد.
await writer.WriteAsync(13);
```

### بحث

کانال‌ها برای انجام نمونه‌برداری ساده مانند این عالی هستند. گزینهٔ `BoundedChannelFullMode.DropOldest` در بسیاری از موارد به‌خصوص مفید است. نمونه‌برداری‌های پیچیده‌تر باید توسط خود مصرف‌کننده‌ها انجام شود.

اگر نیاز به نمونه‌برداری مبتنی بر زمان دارید، مثلاً «فقط 10 آیتم در ثانیه»، از `System.Reactive` استفاده کنید؛ این کتابخانه عملگرهای طبیعی برای کار با زمان را فراهم می‌کند.

> **نکته**
> کانال‌ها در بستهٔ NuGet با نام `System.Threading.Channels` قرار دارند.

### همچنین ببینید

   دستورعمل 9.9 محدودسازی (throttling) کانال‌ها را پوشش می‌دهد که با مسدود کردن تولیدکننده‌ها به‌جای حذف آیتم‌ها، تعداد آیتم‌ها را محدود می‌کند.

   دستورعمل 9.8 استفادهٔ پایه از کانال‌ها را شامل کد تولیدکننده و مصرف‌کننده پوشش می‌دهد.

   دستورعمل 6.4 محدودسازی و نمونه‌برداری با استفاده از `System.Reactive` را پوشش می‌دهد که از نمونه‌برداری مبتنی بر زمان پشتیبانی می‌کند.

---

## ۹.۱۱ پشته‌ها و کیف‌های (Bag) غیرهمزمان

### مسئله

به مجرایی نیاز دارید تا پیام‌ها یا داده‌ها را از بخشی از کد به بخش دیگر منتقل کنید، اما نمی‌خواهید (یا نیازی ندارید) که این مجرا معنای «اول-داخل، اول-خارج» داشته باشد.

### راه‌حل

کتابخانهٔ `Nito.AsyncEx` نوعی به نام `AsyncCollection<T>` فراهم می‌کند که به‌صورت پیش‌فرض مانند یک صف غیرهمزمان عمل می‌کند، اما می‌تواند مانند هر نوع کالکشن تولیدکننده/مصرف‌کننده هم رفتار کند. `AsyncCollection<T>` یک روکش بر روی `IProducerConsumerCollection<T>` است و معادل غیرهمزمان `BlockingCollection<T>` در .NET محسوب می‌شود (که در دستورعمل 9.7 پوشش داده شده است).

`AsyncCollection<T>` از رفتار «آخر-داخل، اول-خارج» (پشته) یا بدون ترتیب (کیف/bag) پشتیبانی می‌کند، بسته به کالکشنی که هنگام ساخت به آن می‌دهید:

```csharp
var _asyncStack = new AsyncCollection<int>(
    new ConcurrentStack<int>());
var _asyncBag = new AsyncCollection<int>(
    new ConcurrentBag<int>());
```

توجه داشته باشید که در مورد ترتیب آیتم‌ها در پشته یک شرط رقابتی وجود دارد. اگر همهٔ تولیدکننده‌ها قبل از شروع مصرف‌کننده‌ها تمام شوند، ترتیب آیتم‌ها مثل یک پشتهٔ معمولی خواهد بود:

```csharp
// کد تولیدکننده
await _asyncStack.AddAsync(7);
await _asyncStack.AddAsync(13);
_asyncStack.CompleteAdding();

// کد مصرف‌کننده
// ابتدا "13" و سپس "7" را نمایش می‌دهد.
while (await _asyncStack.OutputAvailableAsync())
    Trace.WriteLine(await _asyncStack.TakeAsync());
```

وقتی تولیدکننده‌ها و مصرف‌کننده‌ها به‌صورت هم‌زمان اجرا می‌شوند (که حالت عادی است)، مصرف‌کننده همیشه جدیدترین آیتم اضافه‌شده را بعدی دریافت می‌کند. این باعث می‌شود رفتار کلی مجموعه دقیقاً مثل یک پشته نباشد. البته مجموعهٔ `bag` هیچ ترتیب مشخصی ندارد.

`AsyncCollection<T>` از محدودسازی پشتیبانی می‌کند، که در صورتی لازم است که تولیدکننده‌ها ممکن است سریع‌تر از مصرف‌کننده‌ها آیتم اضافه کنند. کافی است مجموعه را با مقدار مناسب بسازید:

```csharp
var _asyncStack = new AsyncCollection<int>(
    new ConcurrentStack<int>(), maxCount: 1);
```

حالا همان کد تولیدکننده به‌صورت غیرهمزمان در صورت نیاز منتظر می‌ماند:

```csharp
// این Add بلافاصله تکمیل می‌شود.
await _asyncStack.AddAsync(7);
// این Add به‌صورت غیرهمزمان منتظر می‌ماند تا مقدار 7 برداشته شود
// سپس مقدار 13 را اضافه می‌کند.
await _asyncStack.AddAsync(13);
_asyncStack.CompleteAdding();
```

کد مثال مصرف‌کننده از `OutputAvailableAsync` استفاده می‌کند که همان محدودیتی را دارد که در دستورعمل 9.8 توضیح داده شد. اگر چند مصرف‌کننده دارید، معمولاً کد مصرف‌کننده به شکل زیر است:

```csharp
while (true)
{
    int item;
    try
    {
        item = await _asyncStack.TakeAsync();
    }
    catch (InvalidOperationException)
    {
        break;
    }
    Trace.WriteLine(item);
}
```

### بحث

`AsyncCollection<T>` در واقع معادل غیرهمزمان `BlockingCollection<T>` است که API کمی متفاوت دارد.

> **نکته**
> نوع `AsyncCollection<T>` در بستهٔ NuGet با نام `Nito.AsyncEx` قرار دارد.

### همچنین ببینید

   دستورعمل 9.8 صف‌های غیرهمزمان را پوشش می‌دهد که بسیار رایج‌تر از پشته‌ها یا کیف‌های غیرهمزمان هستند.

   دستورعمل 9.7 پشته‌ها و کیف‌های همگام (مسدودکننده) را پوشش می‌دهد.



## ۹.۱۲ صف‌های مسدودکننده/غیرهمزمان

### مسئله

به مجرایی نیاز دارید تا پیام‌ها یا داده‌ها را از بخشی از کد به بخش دیگر به‌صورت «اول-داخل، اول-خارج» منتقل کنید، و در عین حال می‌خواهید انعطاف داشته باشید که انتهای تولیدکننده یا انتهای مصرف‌کننده را به‌صورت همگام (سینکرون) یا غیرهمزمان (آسنکرون) رفتار دهید.

برای مثال، یک نخ پس‌زمینه ممکن است داده بارگذاری کند و آن را در مجرا قرار دهد و شما می‌خواهید آن نخ پس‌زمینه در صورت پر بودن مجرا به‌صورت همگام مسدود شود. در همان زمان، نخ UI داده‌ها را از مجرا دریافت می‌کند و شما می‌خواهید نخ UI به‌صورت غیرهمزمان داده‌ها را بکشد تا پاسخ UI حفظ شود.

### راه‌حل

پس از بررسی صف‌های مسدودکننده در دستورعمل 9.6 و صف‌های غیرهمزمان در دستورعمل 9.8، اکنون به چند نوع صف می‌پردازیم که هم API مسدودکننده و هم API غیرهمزمان را پشتیبانی می‌کنند.

اولین گزینه‌ها `BufferBlock<T>` و `ActionBlock<T>` از بستهٔ TPL Dataflow هستند. `BufferBlock<T>` را می‌توان به‌سادگی به‌عنوان یک صف تولیدکننده/مصرف‌کنندهٔ غیرهمزمان به‌کار برد (برای جزئیات بیشتر دستورعمل 9.8 را ببینید):

```csharp
var queue = new BufferBlock<int>();

// کد تولیدکننده (غیرهمزمان)
await queue.SendAsync(7);
await queue.SendAsync(13);
queue.Complete();

// کد مصرف‌کننده برای یک مصرف‌کنندهٔ واحد
while (await queue.OutputAvailableAsync())
    Trace.WriteLine(await queue.ReceiveAsync());

// کد مصرف‌کننده برای چند مصرف‌کننده
while (true)
{
    int item;
    try
    {
        item = await queue.ReceiveAsync();
    }
    catch (InvalidOperationException)
    {
        break;
    }
    Trace.WriteLine(item);
}
```

همان‌طور که در مثال زیر می‌بینید، `BufferBlock<T>` همچنین از API همگام برای هر دو طرف تولیدکننده و مصرف‌کننده پشتیبانی می‌کند:

```csharp
var queue = new BufferBlock<int>();

// کد تولیدکننده (همگام)
queue.Post(7);
queue.Post(13);
queue.Complete();

// کد مصرف‌کننده (همگام)
while (true)
{
    int item;
    try
    {
        item = queue.Receive();
    }
    catch (InvalidOperationException)
    {
        break;
    }
    Trace.WriteLine(item);
}
```

کد مصرف‌کننده هنگام استفاده از `BufferBlock<T>` کمی نامأنوس است، چون نوشتن به سبک «dataflow» معمولاً به شکل دیگری انجام می‌شود. کتابخانهٔ TPL Dataflow تعدادی بلاک دارد که می‌توان آن‌ها را به هم پیوند داد تا یک شبکهٔ واکنشی تعریف کنید. در این حالت، یک صف تولیدکننده/مصرف‌کننده که با یک عمل خاص تکمیل می‌شود را می‌توان با `ActionBlock<T>` تعریف کرد:

```csharp
// کد مصرف‌کننده به سازندهٔ queue پاس داده می‌شود.
ActionBlock<int> queue = new ActionBlock<int>(item =>
    Trace.WriteLine(item));

// تولیدکنندهٔ غیرهمزمان
await queue.SendAsync(7);
await queue.SendAsync(13);

// تولیدکنندهٔ همگام
queue.Post(7);
queue.Post(13);

queue.Complete();
```

اگر کتابخانهٔ TPL Dataflow روی پلتفرم مورد نظر شما در دسترس نباشد، نوع `AsyncProducerConsumerQueue<T>` در Nito.AsyncEx نیز وجود دارد که هر دو متد همگام و غیرهمزمان را پشتیبانی می‌کند:

```csharp
var queue = new AsyncProducerConsumerQueue<int>();

// تولیدکنندهٔ غیرهمزمان
await queue.EnqueueAsync(7);
await queue.EnqueueAsync(13);

// تولیدکنندهٔ همگام
queue.Enqueue(7);
queue.Enqueue(13);

queue.CompleteAdding();

// مصرف‌کنندهٔ غیرهمزمان برای یک مصرف‌کنندهٔ واحد
while (await queue.OutputAvailableAsync())
    Trace.WriteLine(await queue.DequeueAsync());

// مصرف‌کنندهٔ غیرهمزمان برای چند مصرف‌کننده
while (true)
{
    int item;
    try
    {
        item = await queue.DequeueAsync();
    }
    catch (InvalidOperationException)
    {
        break;
    }
    Trace.WriteLine(item);
}

// مصرف‌کنندهٔ همگام
foreach (int item in queue.GetConsumingEnumerable())
    Trace.WriteLine(item);
```

### بحث

توصیه می‌کنم اگر ممکن است از `BufferBlock<T>` یا `ActionBlock<T>` استفاده کنید، زیرا کتابخانهٔ TPL Dataflow معمولاً تست‌شده‌تر و بالغ‌تر از Nito.AsyncEx است. با این حال، `AsyncProducerConsumerQueue<T>` ممکن است مفید باشد اگر برنامهٔ شما از پیش از انواع دیگر AsyncEx استفاده می‌کند.

همچنین می‌توان از `System.Threading.Channels` به‌صورت همگام استفاده کرد، اما فقط به‌طور غیرمستقیم. API طبیعیِ آن‌ها غیرهمزمان است، اما از آن‌جا که آن‌ها مجموعه‌هایی ایمن برای نخ هستند، می‌توانید با قرار دادن کد تولید یا مصرف در داخل `Task.Run` و سپس مسدود کردن روی تسکی که `Task.Run` برمی‌گرداند (مثلاً با `GetAwaiter().GetResult()`) آن‌ها را وادار به کار به‌صورت همگام کنید، مانند این:

```csharp
Channel<int> queue = Channel.CreateBounded<int>(10);

// کد تولیدکننده
ChannelWriter<int> writer = queue.Writer;
Task.Run(async () =>
{
    await writer.WriteAsync(7);
    await writer.WriteAsync(13);
    writer.Complete();
}).GetAwaiter().GetResult();

// کد مصرف‌کننده
ChannelReader<int> reader = queue.Reader;
Task.Run(async () =>
{
    while (await reader.WaitToReadAsync())
        while (reader.TryRead(out int value))
            Trace.WriteLine(value);
}).GetAwaiter().GetResult();
```

بلوک‌های TPL Dataflow، `AsyncProducerConsumerQueue<T>` و `Channels` همگی از محدودسازی (throttling) پشتیبانی می‌کنند که با ارسال گزینه‌ها هنگام ساخت شی فعال می‌شود. محدودسازی وقتی لازم است که تولیدکننده‌ها آیتم‌ها را سریع‌تر از مصرف‌کننده‌ها فشار دهند، زیرا در غیر این صورت ممکن است برنامهٔ شما حافظهٔ زیادی مصرف کند.

> **نکته**
> `BufferBlock<T>` و `ActionBlock<T>` در بستهٔ NuGet با نام `System.Threading.Tasks.Dataflow` قرار دارند. نوع `AsyncProducerConsumerQueue<T>` در بستهٔ `Nito.AsyncEx` موجود است. `Channels` در بستهٔ `System.Threading.Channels` در دسترس‌اند.

### همچنین ببینید

   دستورعمل 9.6 صف‌های تولیدکننده/مصرف‌کنندهٔ مسدودکننده را پوشش می‌دهد.

   دستورعمل 9.8 صف‌های تولیدکننده/مصرف‌کنندهٔ غیرهمزمان را پوشش می‌دهد.

   دستورعمل 5.4 محدودسازی در بلاک‌های dataflow را پوشش می‌دهد.
